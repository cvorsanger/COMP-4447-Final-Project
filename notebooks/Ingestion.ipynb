{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Data Ingestion\n",
    "\n",
    "- [Section 2.1: Motivation](#motivation)\n",
    "- [Section 2.2: Ingestion](#ingestion)\n",
    "- [Section 2.3: Sample ans Explanation](#sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: Motivation <a class=\"anchor\" id=\"motivation\"></a>\n",
    "\n",
    "<p>\n",
    "<img src = https://kss.rs/eng_new/wp-content/uploads/2020/05/tokio.jpg style=\"width:175px;height:250px;margin:0px 10px;\" ALIGN=\"right\" />\n",
    "    <p>A particular interest of the authors are the ongoing Summer Olympic games. We enjoy watching the top athletes in the world compete in sports that are not on television very often; sports like, gymnastics,swimming, and track. A natural curioisty than was to see how other people view the Olympics.</p>    \n",
    "    <p>As social media has grown Twitter has been the go to platform for the world to express their views. Twitter allows for people to express their feelings on just about any subject they desire (for better or for worst). It would make sence then to look at Twitter data to model the sentiment around the Olympics. Luckily Twitter provides an API  for us to query historical tweet data.</p>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: Ingestion <a class=\"anchor\" id=\"ingestion\"></a>\n",
    "\n",
    "The twitter API is a relative easy to use API. There are a few restictions such as rate limits and API types that you do have to consider. For the purposes of this study, the API makes it easy to look at historical tweets containing specific words and hashtags. The follow details certain aspects of the Twitter API that pertains to this project. For more information please visit [here](https://developer.twitter.com/en/docs/twitter-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to get authorization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code:  200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "import base64\n",
    "# Save Authorization Info.\n",
    "client_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXX' #'k7IeaeoVVSVVRs2VMRyjWMGhB'\n",
    "client_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXX'  #'QjWhmf3ylIKXTYn6zv26tTkPjobjbapTKlC4JDay74jd647mcl'\n",
    "bearer_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXX'  #'AAAAAAAAAAAAAAAAAAAAAO3%2BQgEAAAAAKO%2BcZLOP%2B1jh1SeWDdIMpCF4smc%3DiUFDhj7SZfb1fl177n5Fipd9OA2Elj9aVdezk2hhBUGbTrdLgY'\n",
    "key_secret = '{}:{}'.format(client_key, client_secret).encode('ascii')\n",
    "b64_encoded_key = base64.b64encode(key_secret)\n",
    "b64_encoded_key = b64_encoded_key.decode('ascii')\n",
    "\n",
    "# Build API URL \n",
    "base_url = 'https://api.twitter.com/'\n",
    "auth_endpoint = base_url + 'oauth2/token'\n",
    "auth_headers = { 'Authorization': 'Basic {}'.format(b64_encoded_key),\n",
    "                'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8' }\n",
    "auth_data = { 'grant_type': 'client_credentials' }\n",
    "\n",
    "# Provide Authorization Info and Save Access Token\n",
    "response = requests.post(auth_endpoint, headers=auth_headers, data=auth_data)\n",
    "print(\"Response Status Code: \",response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we get a response status code of \"200\". This tells us that we succesfully recieved our access token.\n",
    "\n",
    "Lets get the access token from our response and save it in a variable *access_token*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data =  response.json()\n",
    "access_token = json_data['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utility function was then created. This function allows us to use the twitter API to save tweets. The function needs the users saved access token and allows for the user to specify the number of tweet to pull. The most important parameter of this function is the query parameter. This allows for you filter tweets you recieve by specifing hashtags, words, retweets, etc. For this project we are concerned with tweets containg the hashtags \"#olympics\" and containing the a specific sport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(access_token, query, max_tweets=10, tweet_limit=10):\n",
    "    \"\"\"Retrieve tweets from the recent search API.\n",
    "        Args\n",
    "        ----\n",
    "        access_token (str): A valid bearer token for making Twitter API requests.\n",
    "        query (str): A valid Twitter query string for filtering the search tweets.\n",
    "        max_tweets (int): The maximum number of tweets to collect in total.\n",
    "        tweet_limit (int): The number of maximum tweets per API request. \n",
    "    \"\"\"\n",
    "    page_token = None\n",
    "    tweet_data = []\n",
    "    search_headers = {\n",
    "        'Authorization': 'Bearer {}'.format(access_token),\n",
    "        'User-Agent': 'v2FullArchiveSearchPython',\n",
    "    }\n",
    "    # Divides the max tweets into the appropriate number of requests based on the tweet_limit.\n",
    "    for i in range(max_tweets // tweet_limit - 1):\n",
    "        search_parameters = {\n",
    "            'query': query,\n",
    "            'max_results': tweet_limit,\n",
    "            'tweet.fields': 'lang,created_at,referenced_tweets,source,conversation_id'\n",
    "        }\n",
    "                # If we reach the 2nd page of results, add a next_token attribute to the search parameters\n",
    "        if i > 0:\n",
    "            search_parameters['next_token'] = page_token\n",
    "\n",
    "        response = requests.get(search_url, headers=search_headers, params=search_parameters)\n",
    "        if response.status_code != 200:\n",
    "            print(f'\\tError occurred: Status Code{response.status_code}: {response.text}')\n",
    "        else:\n",
    "            # We need to check for a result count before doing anything futher; if we have result_count we have data\n",
    "            if response.json()['meta']['result_count'] > 0:\n",
    "                tweet_data.extend(response.json()['data'])\n",
    "                \n",
    "                # If a 'next_token' exists, then update the page token to continue pagination through results\n",
    "                if 'next_token' in response.json()['meta']:\n",
    "                    page_token = response.json()['meta']['next_token']\n",
    "            else:\n",
    "                print(f'\\tNo data returned for query!')\n",
    "                break        \n",
    "        print(f'\\t{len(tweet_data)} total tweets gathered')\n",
    "        time.sleep(1)\n",
    "    return tweet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function we can sample retweets having to do with olympic gymnastics. Notice that we are specify the hashtag \"#olympics\", the word \"gymnastics\" and is a retweet in the query parameter. Finally, so we do have to keep requesting data from the twitter API we save the tweets in a pickle file. This way we can use them later in our anaysis (and twitter will not get made at us)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the request\n",
    "q = '#olympics gymnastics -is:retweet'\n",
    "olympic_tweets = get_tweets(access_token, q, max_tweets=5000, tweet_limit=100)\n",
    "\n",
    "with open('../data/gymnastics-tweets.pkl', 'wb') as f:\n",
    "\tpickle.dump(olympic_tweets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the \"get_tweets\" function we tried to pull 5000 tweets for the sports basketball, biking, diving, gymnastics, skateboarding, surfing, track, volleyball, and cycling. This was easily doen by changing the querey parameter to include the name of the sport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3: Sample and Explanation <a class=\"anchor\" id=\"sample\"></a>\n",
    "\n",
    "Alright we have pulled in some tweets. Now lets have a look at some of the original tweets and the retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>@ThatMamaClub @LovingBlogs @RTBlogRoyalty @sin...</td>\n",
       "      <td>1423974993180909569</td>\n",
       "      <td>2021-08-07T11:51:09.000Z</td>\n",
       "      <td>1423894220885082113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>@BlackettMusic @rtArtBoost @BlackettPromo Than...</td>\n",
       "      <td>1423601048623648769</td>\n",
       "      <td>2021-08-06T11:05:13.000Z</td>\n",
       "      <td>1423511652062797824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>I'm tired of people who decide to themselves w...</td>\n",
       "      <td>1424245348579495940</td>\n",
       "      <td>2021-08-08T05:45:26.000Z</td>\n",
       "      <td>1424245348579495940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>@faizaaaaaaa_1 Thank You, Simone Biles - Headp...</td>\n",
       "      <td>1423419204577988618</td>\n",
       "      <td>2021-08-05T23:02:38.000Z</td>\n",
       "      <td>1423371318825734145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>#Wrestlympics - Gymnastics: Floor Exercise\\n\\n...</td>\n",
       "      <td>1423386446879203328</td>\n",
       "      <td>2021-08-05T20:52:28.000Z</td>\n",
       "      <td>1423386446879203328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text                   id                created_at      conversation_id\n",
       "734   @ThatMamaClub @LovingBlogs @RTBlogRoyalty @sin...  1423974993180909569  2021-08-07T11:51:09.000Z  1423894220885082113\n",
       "1215  @BlackettMusic @rtArtBoost @BlackettPromo Than...  1423601048623648769  2021-08-06T11:05:13.000Z  1423511652062797824\n",
       "348   I'm tired of people who decide to themselves w...  1424245348579495940  2021-08-08T05:45:26.000Z  1424245348579495940\n",
       "1549  @faizaaaaaaa_1 Thank You, Simone Biles - Headp...  1423419204577988618  2021-08-05T23:02:38.000Z  1423371318825734145\n",
       "3501  #Wrestlympics - Gymnastics: Floor Exercise\\n\\n...  1423386446879203328  2021-08-05T20:52:28.000Z  1423386446879203328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "original_tweets_df = pd.DataFrame(pd.read_pickle('../data/gymnastics-tweets.pkl'))\n",
    "original_tweets_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is  a lot of information about tweets that you recieve. For us the most important ones are:\n",
    "\n",
    "- text - The text of the tweet sent out. This will include user handles, hastags, emojis, and any retweet indicators\n",
    "- id - The unique id given to the tweet. This allows for twitter to store tweets.\n",
    "- created_at - When the tweet was tweeted. Given in UTC time.\n",
    "- conversation_id - The unique id given to twitter conversations. We can use this id to get all tweets in an conversation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"container\">\n",
    "   <div style=\"float:left;width:20%\"><a href=\"./Intro.ipynb\"><< Section 1: Introduction</a></div>\n",
    "   <div style=\"float:right;width:20%\"><a href=\"./Cleaning.ipynb\">Section 3: Data Cleaning >></a></div>\n",
    "   <div style=\"float:right;width:40%\"><a href=\"../main.md\">Table of Contents</a></div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5740b0c65ce1535d49f8104bf53e2dbf28aba8cf44c23304f5a7991b903c1ba"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
