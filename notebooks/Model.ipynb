{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Section 4: Model Creation\n",
    "\n",
    "- [Section 4.1: Model](#model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4.1: Model <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "### Background\n",
    "\n",
    "To provide sentiment analysis for tweet data, we utilize two packages: (1) TextBlob and (2) VADER from the NLTK toolkit. TextBlob provides a simple interface for processing text-based data and allows for the calculation of the subjectivity and polarity for a given text, which will aid in sentiment analysis using a set of additional text features. The VADER model is a pre-trained model that uses rule-based values which are especially attuned to sentiments from social media, making it a great choice for overall sentiment analysis. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read data from pickled checkpoint\n",
    "olympic_df = pd.read_pickle('../data/checkpoints/olympic-tweets-pre-sentiment.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Lemmatize prior to sentiment analysis\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "olympic_df['lemma_text'] = olympic_df.clean_no_stops.apply(\n",
    "\tlambda text: [ wn_lemmatizer.lemmatize(word, pos='v') for word in text ]\n",
    ")\n",
    "olympic_df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               id                created_at  conversation_id  \\\n",
       "23659  -179023860 2021-08-07 12:19:39+00:00       -179023860   \n",
       "9814  -1458102269 2021-07-25 13:02:10+00:00                0   \n",
       "4984   -891924480 2021-08-01 07:59:35+00:00                0   \n",
       "26683 -1621647360 2021-08-08 06:02:52+00:00      -1621647360   \n",
       "5418   1532305413 2021-07-30 14:44:54+00:00                0   \n",
       "\n",
       "                                                    text       sport  \\\n",
       "23659  #NeerajChopra created History by bringing home...       track   \n",
       "9814   RT @BernardNdong: Austria's #AnnKiesenhofer wo...      biking   \n",
       "4984   Updated medal table for cycling disciplines (e...      biking   \n",
       "26683  The United States completely outplays Brazil i...  volleyball   \n",
       "5418   RT @jindadilkashmir: #Mantarbug Army camp orga...      biking   \n",
       "\n",
       "                                              clean_text  \\\n",
       "23659   created history by bringing home first ever t...   \n",
       "9814   rt  austrias  won the womens road race gold   ...   \n",
       "4984   updated medal table for cycling disciplines ex...   \n",
       "26683  the united states completely outplays brazil i...   \n",
       "5418   rt   army camp organized a cycling race for th...   \n",
       "\n",
       "                                          clean_no_stops  \\\n",
       "23659  [created, history, bringing, home, first, ever...   \n",
       "9814   [rt, austrias, womens, road, race, gold, phd, ...   \n",
       "4984   [updated, medal, table, cycling, disciplines, ...   \n",
       "26683  [united, states, completely, outplays, brazil,...   \n",
       "5418   [rt, army, camp, organized, cycling, race, nex...   \n",
       "\n",
       "                                              lemma_text  \n",
       "23659  [create, history, bring, home, first, ever, tr...  \n",
       "9814   [rt, austrias, womens, road, race, gold, phd, ...  \n",
       "4984   [update, medal, table, cycle, discipline, excl...  \n",
       "26683  [unite, state, completely, outplay, brazil, wo...  \n",
       "5418   [rt, army, camp, organize, cycle, race, next, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23659</th>\n",
       "      <td>-179023860</td>\n",
       "      <td>2021-08-07 12:19:39+00:00</td>\n",
       "      <td>-179023860</td>\n",
       "      <td>#NeerajChopra created History by bringing home...</td>\n",
       "      <td>track</td>\n",
       "      <td>created history by bringing home first ever t...</td>\n",
       "      <td>[created, history, bringing, home, first, ever...</td>\n",
       "      <td>[create, history, bring, home, first, ever, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>-1458102269</td>\n",
       "      <td>2021-07-25 13:02:10+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @BernardNdong: Austria's #AnnKiesenhofer wo...</td>\n",
       "      <td>biking</td>\n",
       "      <td>rt  austrias  won the womens road race gold   ...</td>\n",
       "      <td>[rt, austrias, womens, road, race, gold, phd, ...</td>\n",
       "      <td>[rt, austrias, womens, road, race, gold, phd, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>-891924480</td>\n",
       "      <td>2021-08-01 07:59:35+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Updated medal table for cycling disciplines (e...</td>\n",
       "      <td>biking</td>\n",
       "      <td>updated medal table for cycling disciplines ex...</td>\n",
       "      <td>[updated, medal, table, cycling, disciplines, ...</td>\n",
       "      <td>[update, medal, table, cycle, discipline, excl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26683</th>\n",
       "      <td>-1621647360</td>\n",
       "      <td>2021-08-08 06:02:52+00:00</td>\n",
       "      <td>-1621647360</td>\n",
       "      <td>The United States completely outplays Brazil i...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>the united states completely outplays brazil i...</td>\n",
       "      <td>[united, states, completely, outplays, brazil,...</td>\n",
       "      <td>[unite, state, completely, outplay, brazil, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>1532305413</td>\n",
       "      <td>2021-07-30 14:44:54+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @jindadilkashmir: #Mantarbug Army camp orga...</td>\n",
       "      <td>biking</td>\n",
       "      <td>rt   army camp organized a cycling race for th...</td>\n",
       "      <td>[rt, army, camp, organized, cycling, race, nex...</td>\n",
       "      <td>[rt, army, camp, organize, cycle, race, next, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentiment Calculation\n",
    "\n",
    "From the output of TextBlob, we generate two additional features for use in our analysis:\n",
    "* Polarity: a measure ([-1, 1]) of the sentiment of a text; higher polarity means the text contains more positive sentiment.\n",
    "* Subjectivity: a measure ([0, 1]) of the opinion and factual information contained in a text; higher subjectivity means the text contains more personal opinion.\n",
    "\n",
    "From the output of VADER, we generate three additional features for use in our analysis:\n",
    "* Neg, Neu, and Pos are scores for the ratios for proportions of text that fall into a negative, neutral, and positive sentiment.\n",
    "* Compound: a score computed by summing the valence scores of each word in the VADER lexicon and normalized to create a composite sentiment score.\n",
    "* Sentiment: a categorical column that standardizes/generalizes the compound score into positive, neutral, and negative sentiment values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Calculating polarity and subjectivity\n",
    "olympic_df[['polarity', 'subjectivity']] = olympic_df['lemma_text'].apply(\n",
    "\tlambda text: pd.Series(TextBlob(' '.join(text)).sentiment)\n",
    ")\n",
    "\n",
    "# Calculating Negative, Positive, Neutral and Compound values\n",
    "for index, row in olympic_df['clean_no_stops'].iteritems():\n",
    "\tscore = SentimentIntensityAnalyzer().polarity_scores(' '.join(row))\n",
    "\tneg = score['neg']\n",
    "\tneu = score['neu']\n",
    "\tpos = score['pos']\n",
    "\tcomp = score['compound']\n",
    "\n",
    "\tif comp <= -0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'negative'\n",
    "\telif comp >= 0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'positive'\n",
    "\telse:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'neutral'\n",
    "\t# # Set the values as columns\n",
    "\tolympic_df.loc[index, 'neg'] = neg\n",
    "\tolympic_df.loc[index, 'neu'] = neu\n",
    "\tolympic_df.loc[index, 'pos'] = pos\n",
    "\tolympic_df.loc[index, 'compound'] = comp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A sample of data running our model we will get:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "olympic_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id                created_at  conversation_id  \\\n",
       "0 -1349054463 2021-08-12 18:15:03+00:00      -1349054463   \n",
       "1   429334529 2021-08-12 15:23:44+00:00        429334529   \n",
       "2   -48885760 2021-08-12 14:54:47+00:00        -48885760   \n",
       "3  2115334144 2021-08-12 13:02:47+00:00       2115334144   \n",
       "4  -183029759 2021-08-12 12:36:07+00:00       -183029759   \n",
       "5 -1944776702 2021-08-12 12:26:43+00:00      -1944776702   \n",
       "6   -73945082 2021-08-12 11:49:10+00:00        -73945082   \n",
       "7   156741635 2021-08-12 11:16:04+00:00        156741635   \n",
       "8   517304321 2021-08-12 03:47:08+00:00        517304321   \n",
       "9  -623542263 2021-08-12 01:55:52+00:00       -623542263   \n",
       "\n",
       "                                                text       sport  \\\n",
       "0  Congratulations toüèÖChelsea GrayüèÖon bringing ho...  basketball   \n",
       "1  Talkin‚Äô Noise Podcast - Ep. 9. Will #TeamUSA  ...  basketball   \n",
       "2  üî•üî• High Stakes Takes Locks üî•üî•\\n\\nSTILL on a 12...  basketball   \n",
       "3  Thursday Q&amp;A\\n\\nClick the link in the bio!...  basketball   \n",
       "4  My 1st of three #Olympics themed articles in t...  basketball   \n",
       "5  Great little video about the legend that is Pa...  basketball   \n",
       "6  &gt;US womens basketball team: 7 gold medals \\...  basketball   \n",
       "7  Celebrate the #Olympics by watching #sport mov...  basketball   \n",
       "8  new fc #Dynamite #Olympics #LoveIsland #loveis...  basketball   \n",
       "9  CyberSketch 185\\n\\nDamian Lillard #NBA \\n@Dame...  basketball   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  congratulations tochelsea grayon bringing home...   \n",
       "1  talkin noise podcast  ep  will   basketball te...   \n",
       "2   high stakes takes locks still on a  day strea...   \n",
       "3  thursday qampaclick the link in the bio       ...   \n",
       "4  my st of three  themed articles in this weeks ...   \n",
       "5  great little video about the legend that is pa...   \n",
       "6  gtus womens basketball team  gold medals gtale...   \n",
       "7  celebrate the  by watching  movies            ...   \n",
       "8                          new fc                      \n",
       "9  cybersketch damian lillard    link in bio     ...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [congratulations, tochelsea, grayon, bringing,...   \n",
       "1  [talkin, noise, podcast, ep, basketball, team,...   \n",
       "2  [high, stakes, takes, locks, still, day, strea...   \n",
       "3                  [thursday, qampaclick, link, bio]   \n",
       "4  [st, three, themed, articles, weeks, focuses, ...   \n",
       "5  [great, little, video, legend, patty, looking,...   \n",
       "6  [gtus, womens, basketball, team, gold, medals,...   \n",
       "7                      [celebrate, watching, movies]   \n",
       "8                                          [new, fc]   \n",
       "9          [cybersketch, damian, lillard, link, bio]   \n",
       "\n",
       "                                          lemma_text  polarity  subjectivity  \\\n",
       "0  [congratulations, tochelsea, grayon, bring, ho...  1.000000      1.000000   \n",
       "1  [talkin, noise, podcast, ep, basketball, team,...  0.650000      0.650000   \n",
       "2  [high, stake, take, lock, still, day, streak, ...  0.144242      0.513333   \n",
       "3                  [thursday, qampaclick, link, bio]  0.000000      0.000000   \n",
       "4  [st, three, theme, article, weeks, focus, amaz...  0.500000      0.400000   \n",
       "5  [great, little, video, legend, patty, look, li...  0.146250      0.572500   \n",
       "6  [gtus, womens, basketball, team, gold, medals,...  0.316667      0.408333   \n",
       "7                         [celebrate, watch, movies]  0.000000      0.000000   \n",
       "8                                          [new, fc]  0.136364      0.454545   \n",
       "9          [cybersketch, damian, lillard, link, bio]  0.000000      0.000000   \n",
       "\n",
       "  sentiment  neg    neu    pos  compound  \n",
       "0  positive  0.0  0.456  0.544    0.9493  \n",
       "1  positive  0.0  0.678  0.322    0.5859  \n",
       "2  positive  0.0  0.865  0.135    0.4215  \n",
       "3   neutral  0.0  1.000  0.000    0.0000  \n",
       "4  positive  0.0  0.598  0.402    0.8555  \n",
       "5  positive  0.0  0.661  0.339    0.6249  \n",
       "6  positive  0.0  0.680  0.320    0.7650  \n",
       "7  positive  0.0  0.351  0.649    0.5719  \n",
       "8   neutral  0.0  1.000  0.000    0.0000  \n",
       "9   neutral  0.0  1.000  0.000    0.0000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1349054463</td>\n",
       "      <td>2021-08-12 18:15:03+00:00</td>\n",
       "      <td>-1349054463</td>\n",
       "      <td>Congratulations toüèÖChelsea GrayüèÖon bringing ho...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>congratulations tochelsea grayon bringing home...</td>\n",
       "      <td>[congratulations, tochelsea, grayon, bringing,...</td>\n",
       "      <td>[congratulations, tochelsea, grayon, bring, ho...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429334529</td>\n",
       "      <td>2021-08-12 15:23:44+00:00</td>\n",
       "      <td>429334529</td>\n",
       "      <td>Talkin‚Äô Noise Podcast - Ep. 9. Will #TeamUSA  ...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>talkin noise podcast  ep  will   basketball te...</td>\n",
       "      <td>[talkin, noise, podcast, ep, basketball, team,...</td>\n",
       "      <td>[talkin, noise, podcast, ep, basketball, team,...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48885760</td>\n",
       "      <td>2021-08-12 14:54:47+00:00</td>\n",
       "      <td>-48885760</td>\n",
       "      <td>üî•üî• High Stakes Takes Locks üî•üî•\\n\\nSTILL on a 12...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>high stakes takes locks still on a  day strea...</td>\n",
       "      <td>[high, stakes, takes, locks, still, day, strea...</td>\n",
       "      <td>[high, stake, take, lock, still, day, streak, ...</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2115334144</td>\n",
       "      <td>2021-08-12 13:02:47+00:00</td>\n",
       "      <td>2115334144</td>\n",
       "      <td>Thursday Q&amp;amp;A\\n\\nClick the link in the bio!...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>thursday qampaclick the link in the bio       ...</td>\n",
       "      <td>[thursday, qampaclick, link, bio]</td>\n",
       "      <td>[thursday, qampaclick, link, bio]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-183029759</td>\n",
       "      <td>2021-08-12 12:36:07+00:00</td>\n",
       "      <td>-183029759</td>\n",
       "      <td>My 1st of three #Olympics themed articles in t...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>my st of three  themed articles in this weeks ...</td>\n",
       "      <td>[st, three, themed, articles, weeks, focuses, ...</td>\n",
       "      <td>[st, three, theme, article, weeks, focus, amaz...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1944776702</td>\n",
       "      <td>2021-08-12 12:26:43+00:00</td>\n",
       "      <td>-1944776702</td>\n",
       "      <td>Great little video about the legend that is Pa...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>great little video about the legend that is pa...</td>\n",
       "      <td>[great, little, video, legend, patty, looking,...</td>\n",
       "      <td>[great, little, video, legend, patty, look, li...</td>\n",
       "      <td>0.146250</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-73945082</td>\n",
       "      <td>2021-08-12 11:49:10+00:00</td>\n",
       "      <td>-73945082</td>\n",
       "      <td>&amp;gt;US womens basketball team: 7 gold medals \\...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>gtus womens basketball team  gold medals gtale...</td>\n",
       "      <td>[gtus, womens, basketball, team, gold, medals,...</td>\n",
       "      <td>[gtus, womens, basketball, team, gold, medals,...</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156741635</td>\n",
       "      <td>2021-08-12 11:16:04+00:00</td>\n",
       "      <td>156741635</td>\n",
       "      <td>Celebrate the #Olympics by watching #sport mov...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>celebrate the  by watching  movies            ...</td>\n",
       "      <td>[celebrate, watching, movies]</td>\n",
       "      <td>[celebrate, watch, movies]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>517304321</td>\n",
       "      <td>2021-08-12 03:47:08+00:00</td>\n",
       "      <td>517304321</td>\n",
       "      <td>new fc #Dynamite #Olympics #LoveIsland #loveis...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>new fc</td>\n",
       "      <td>[new, fc]</td>\n",
       "      <td>[new, fc]</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-623542263</td>\n",
       "      <td>2021-08-12 01:55:52+00:00</td>\n",
       "      <td>-623542263</td>\n",
       "      <td>CyberSketch 185\\n\\nDamian Lillard #NBA \\n@Dame...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>cybersketch damian lillard    link in bio     ...</td>\n",
       "      <td>[cybersketch, damian, lillard, link, bio]</td>\n",
       "      <td>[cybersketch, damian, lillard, link, bio]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Cache results\n",
    "with open('../data/checkpoints/olympic-tweets-post-sentiment.pkl', 'wb') as f:\n",
    "\tpickle.dump(olympic_df, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"container\">\n",
    "   <div style=\"float:left;width:20%\"><a href=\"./Cleaning.ipynb\"><< Section 3: Data Cleaning</a></div>\n",
    "   <div style=\"float:right;width:25%\"><a href=\"./Eval.ipynb\">Section 5: Evaluation and Conclusions >></a></div>\n",
    "   <div style=\"float:right;width:35%\"><a href=\"../main.md\">Table of Contents</a></div>\n",
    "</div>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('DSFinal': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "17c2d29f20849e0234e28d332614864f502d155aa05f82293e2dffbbaf220632"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}