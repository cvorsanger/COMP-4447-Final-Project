{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Section 4: Model Creation\n",
    "\n",
    "- [Section 4.1: Model](#model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4.1: Model <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "### Background\n",
    "\n",
    "To provide sentiment analysis for tweet data, we utilize two packages: (1) TextBlob and (2) VADER from the NLTK toolkit. TextBlob provides a simple interface for processing text-based data and allows for the calculation of the subjectivity and polarity for a given text, which will aid in sentiment analysis using a set of additional text features. The VADER model is a pre-trained model that uses rule-based values which are especially attuned to sentiments from social media, making it a great choice for overall sentiment analysis. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Read data from pickled checkpoint\n",
    "olympic_df = pd.read_pickle('../data/checkpoints/olympic-tweets-pre-sentiment.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Lemmatize prior to sentiment analysis\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "olympic_df['lemma_text'] = olympic_df.clean_no_stops.apply(lambda text: [ wn_lemmatizer.lemmatize(word, pos='v') for word in text ])\n",
    "olympic_df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               id                created_at  conversation_id  \\\n",
       "5254   2102861828 2021-07-31 08:30:15+00:00                0   \n",
       "29926 -1651146750 2021-08-06 05:20:18+00:00      -1651146750   \n",
       "27009  -736866304 2021-08-08 05:54:22+00:00       1666478086   \n",
       "9187   2035789834 2021-07-26 07:21:37+00:00                0   \n",
       "25152  1553350657 2021-08-06 08:21:22+00:00       1553350657   \n",
       "\n",
       "                                                    text       sport  \\\n",
       "5254   RT @Netwerk24Sport: BMX-ryer uit intensiewe so...      biking   \n",
       "29926  Beach volleyball is quickly becoming my favori...  volleyball   \n",
       "27009  Team USA is throttling a very good Brazil team...  volleyball   \n",
       "9187   I have to make sure that I don’t miss the indo...      biking   \n",
       "25152  Madison time! YAS!\\n\\nIf you fancy watching th...       track   \n",
       "\n",
       "                                              clean_text  \\\n",
       "5254               rt  bmxryer uit intensiewe sorg         \n",
       "29926  beach volleyball is quickly becoming my favori...   \n",
       "27009  team usa is throttling a very good brazil team...   \n",
       "9187   i have to make sure that i dont miss the indoo...   \n",
       "25152  madison time yasif you fancy watching the most...   \n",
       "\n",
       "                                          clean_no_stops  \\\n",
       "5254                [rt, bmxryer, uit, intensiewe, sorg]   \n",
       "29926  [beach, volleyball, quickly, becoming, favorit...   \n",
       "27009  [team, usa, throttling, good, brazil, team, am...   \n",
       "9187   [make, sure, dont, miss, indoor, cycling, when...   \n",
       "25152  [madison, time, yasif, fancy, watching, exciti...   \n",
       "\n",
       "                                              lemma_text  \n",
       "5254                [rt, bmxryer, uit, intensiewe, sorg]  \n",
       "29926  [beach, volleyball, quickly, become, favorite,...  \n",
       "27009   [team, usa, throttle, good, brazil, team, amaze]  \n",
       "9187   [make, sure, dont, miss, indoor, cycle, whenev...  \n",
       "25152  [madison, time, yasif, fancy, watch, excite, c...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>2102861828</td>\n",
       "      <td>2021-07-31 08:30:15+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @Netwerk24Sport: BMX-ryer uit intensiewe so...</td>\n",
       "      <td>biking</td>\n",
       "      <td>rt  bmxryer uit intensiewe sorg</td>\n",
       "      <td>[rt, bmxryer, uit, intensiewe, sorg]</td>\n",
       "      <td>[rt, bmxryer, uit, intensiewe, sorg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29926</th>\n",
       "      <td>-1651146750</td>\n",
       "      <td>2021-08-06 05:20:18+00:00</td>\n",
       "      <td>-1651146750</td>\n",
       "      <td>Beach volleyball is quickly becoming my favori...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>beach volleyball is quickly becoming my favori...</td>\n",
       "      <td>[beach, volleyball, quickly, becoming, favorit...</td>\n",
       "      <td>[beach, volleyball, quickly, become, favorite,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27009</th>\n",
       "      <td>-736866304</td>\n",
       "      <td>2021-08-08 05:54:22+00:00</td>\n",
       "      <td>1666478086</td>\n",
       "      <td>Team USA is throttling a very good Brazil team...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>team usa is throttling a very good brazil team...</td>\n",
       "      <td>[team, usa, throttling, good, brazil, team, am...</td>\n",
       "      <td>[team, usa, throttle, good, brazil, team, amaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>2035789834</td>\n",
       "      <td>2021-07-26 07:21:37+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>I have to make sure that I don’t miss the indo...</td>\n",
       "      <td>biking</td>\n",
       "      <td>i have to make sure that i dont miss the indoo...</td>\n",
       "      <td>[make, sure, dont, miss, indoor, cycling, when...</td>\n",
       "      <td>[make, sure, dont, miss, indoor, cycle, whenev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25152</th>\n",
       "      <td>1553350657</td>\n",
       "      <td>2021-08-06 08:21:22+00:00</td>\n",
       "      <td>1553350657</td>\n",
       "      <td>Madison time! YAS!\\n\\nIf you fancy watching th...</td>\n",
       "      <td>track</td>\n",
       "      <td>madison time yasif you fancy watching the most...</td>\n",
       "      <td>[madison, time, yasif, fancy, watching, exciti...</td>\n",
       "      <td>[madison, time, yasif, fancy, watch, excite, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentiment Calculation\n",
    "\n",
    "From the output of TextBlob, we generate two additional features for use in our analysis:\n",
    "* Polarity: a measure ([-1, 1]) of the sentiment of a text; higher polarity means the text contains more positive sentiment.\n",
    "* Subjectivity: a measure ([0, 1]) of the opinion and factual information contained in a text; higher subjectivity means the text contains more personal opinion.\n",
    "\n",
    "From the output of VADER, we generate three additional features for use in our analysis:\n",
    "* Neg, Neu, and Pos are scores for the ratios for proportions of text that fall into a negative, neutral, and positive sentiment.\n",
    "* Compound: a score computed by summing the valence scores of each word in the VADER lexicon and normalized to create a composite sentiment score.\n",
    "* Sentiment: a categorical column that standardizes/generalizes the compound score into positive, neutral, and negative sentiment values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Calculating polarity and subjectivity\n",
    "olympic_df[['polarity', 'subjectivity']] = olympic_df['lemma_text'].apply(lambda text: pd.Series(TextBlob(' '.join(text)).sentiment))\n",
    "\n",
    "# Calculating Negative, Positive, Neutral and Compound values\n",
    "for index, row in olympic_df['clean_no_stops'].iteritems():\n",
    "\tscore = SentimentIntensityAnalyzer().polarity_scores(' '.join(row))\n",
    "\tneg = score['neg']\n",
    "\tneu = score['neu']\n",
    "\tpos = score['pos']\n",
    "\tcomp = score['compound']\n",
    "\n",
    "\tif comp <= -0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'negative'\n",
    "\telif comp >= 0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'positive'\n",
    "\telif comp < 0.05 and comp > -0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'neutral'\n",
    "\t# # Set the values as columns\n",
    "\tolympic_df.loc[index, 'neg'] = neg\n",
    "\tolympic_df.loc[index, 'neu'] = neu\n",
    "\tolympic_df.loc[index, 'pos'] = pos\n",
    "\tolympic_df.loc[index, 'compound'] = comp\n",
    "\n",
    "olympic_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-0566d46d3d34>, line 16)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-0566d46d3d34>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    elif:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cache results\n",
    "with open('../data/checkpoints/olympic-tweets-post-sentiment.pkl', 'wb') as f:\n",
    "\tpickle.dump(olympic_df, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"container\">\n",
    "   <div style=\"float:left;width:20%\"><a href=\"./Cleaning.ipynb\"><< Section 3: Data Cleaning</a></div>\n",
    "   <div style=\"float:right;width:25%\"><a href=\"./Eval.ipynb\">Section 5: Evaluation and Conclusions >></a></div>\n",
    "   <div style=\"float:right;width:35%\"><a href=\"../main.md\">Table of Contents</a></div>\n",
    "</div>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}