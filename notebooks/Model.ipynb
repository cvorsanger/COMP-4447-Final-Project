{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Section 4: Model Creation\n",
    "\n",
    "- [Section 4.1: Model](#model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4.1: Model <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "### Background\n",
    "\n",
    "To provide sentiment analysis for tweet data, we utilize two packages: (1) TextBlob and (2) VADER from the NLTK toolkit. TextBlob provides a simple interface for processing text-based data and allows for the calculation of the subjectivity and polarity for a given text, which will aid in sentiment analysis using a set of additional text features. The VADER model is a pre-trained model that uses rule-based values which are especially attuned to sentiments from social media, making it a great choice for overall sentiment analysis. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read data from pickled checkpoint\n",
    "olympic_df = pd.read_pickle('../data/checkpoints/olympic-tweets-pre-sentiment.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Lemmatize prior to sentiment analysis\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "olympic_df['lemma_text'] = olympic_df.clean_no_stops.apply(\n",
    "\tlambda text: [ wn_lemmatizer.lemmatize(word, pos='v') for word in text ]\n",
    ")\n",
    "olympic_df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               id                created_at  conversation_id  \\\n",
       "8496    567746572 2021-07-27 08:03:56+00:00                0   \n",
       "23035   659890179 2021-08-07 12:58:50+00:00        659890179   \n",
       "26240 -1235767292 2021-08-08 06:43:29+00:00      -1235767292   \n",
       "6299   -719900667 2021-07-29 12:28:34+00:00                0   \n",
       "14800  1654067200 2021-08-06 04:42:01+00:00       1654067200   \n",
       "\n",
       "                                                    text       sport  \\\n",
       "8496   Local authority says get on your bike this wee...      biking   \n",
       "23035  #TokyoOlympics : Neeraj Chopra creates history...       track   \n",
       "26240  What‚Äôs #Best today on https://t.co/UOD7arDCSd ...  volleyball   \n",
       "6299   RT @Clarsonimus: \"Elitism is the #slur directe...      biking   \n",
       "14800  The screen says Artistic Swimming, yet here I ...  gymnastics   \n",
       "\n",
       "                                              clean_text  \\\n",
       "8496   local authority says get on your bike this wee...   \n",
       "23035    neeraj chopra creates history picks first go...   \n",
       "26240  whats  today on  laurent tillie  french male v...   \n",
       "6299   rt  elitism is the  directed at merit by medio...   \n",
       "14800  the screen says artistic swimming yet here i a...   \n",
       "\n",
       "                                          clean_no_stops  \\\n",
       "8496        [local, authority, says, get, bike, weekend]   \n",
       "23035  [neeraj, chopra, creates, history, picks, firs...   \n",
       "26240  [whats, today, laurent, tillie, french, male, ...   \n",
       "6299          [rt, elitism, directed, merit, mediocrity]   \n",
       "14800  [screen, says, artistic, swimming, yet, still,...   \n",
       "\n",
       "                                              lemma_text  \n",
       "8496         [local, authority, say, get, bike, weekend]  \n",
       "23035  [neeraj, chopra, create, history, pick, first,...  \n",
       "26240  [whats, today, laurent, tillie, french, male, ...  \n",
       "6299            [rt, elitism, direct, merit, mediocrity]  \n",
       "14800  [screen, say, artistic, swim, yet, still, watc...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>567746572</td>\n",
       "      <td>2021-07-27 08:03:56+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Local authority says get on your bike this wee...</td>\n",
       "      <td>biking</td>\n",
       "      <td>local authority says get on your bike this wee...</td>\n",
       "      <td>[local, authority, says, get, bike, weekend]</td>\n",
       "      <td>[local, authority, say, get, bike, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23035</th>\n",
       "      <td>659890179</td>\n",
       "      <td>2021-08-07 12:58:50+00:00</td>\n",
       "      <td>659890179</td>\n",
       "      <td>#TokyoOlympics : Neeraj Chopra creates history...</td>\n",
       "      <td>track</td>\n",
       "      <td>neeraj chopra creates history picks first go...</td>\n",
       "      <td>[neeraj, chopra, creates, history, picks, firs...</td>\n",
       "      <td>[neeraj, chopra, create, history, pick, first,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26240</th>\n",
       "      <td>-1235767292</td>\n",
       "      <td>2021-08-08 06:43:29+00:00</td>\n",
       "      <td>-1235767292</td>\n",
       "      <td>What‚Äôs #Best today on https://t.co/UOD7arDCSd ...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>whats  today on  laurent tillie  french male v...</td>\n",
       "      <td>[whats, today, laurent, tillie, french, male, ...</td>\n",
       "      <td>[whats, today, laurent, tillie, french, male, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>-719900667</td>\n",
       "      <td>2021-07-29 12:28:34+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @Clarsonimus: \"Elitism is the #slur directe...</td>\n",
       "      <td>biking</td>\n",
       "      <td>rt  elitism is the  directed at merit by medio...</td>\n",
       "      <td>[rt, elitism, directed, merit, mediocrity]</td>\n",
       "      <td>[rt, elitism, direct, merit, mediocrity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>1654067200</td>\n",
       "      <td>2021-08-06 04:42:01+00:00</td>\n",
       "      <td>1654067200</td>\n",
       "      <td>The screen says Artistic Swimming, yet here I ...</td>\n",
       "      <td>gymnastics</td>\n",
       "      <td>the screen says artistic swimming yet here i a...</td>\n",
       "      <td>[screen, says, artistic, swimming, yet, still,...</td>\n",
       "      <td>[screen, say, artistic, swim, yet, still, watc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentiment Calculation\n",
    "\n",
    "From the output of TextBlob, we generate two additional features for use in our analysis:\n",
    "* Polarity: a measure ([-1, 1]) of the sentiment of a text; higher polarity means the text contains more positive sentiment.\n",
    "* Subjectivity: a measure ([0, 1]) of the opinion and factual information contained in a text; higher subjectivity means the text contains more personal opinion.\n",
    "\n",
    "From the output of VADER, we generate three additional features for use in our analysis:\n",
    "* Neg, Neu, and Pos are scores for the ratios for proportions of text that fall into a negative, neutral, and positive sentiment.\n",
    "* Compound: a score computed by summing the valence scores of each word in the VADER lexicon and normalized to create a composite sentiment score.\n",
    "* Sentiment: a categorical column that standardizes/generalizes the compound score into positive, neutral, and negative sentiment values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Calculating polarity and subjectivity\n",
    "olympic_df[['polarity', 'subjectivity']] = olympic_df['lemma_text'].apply(\n",
    "\tlambda text: pd.Series(TextBlob(' '.join(text)).sentiment)\n",
    ")\n",
    "\n",
    "# Calculating Negative, Positive, Neutral and Compound values\n",
    "for index, row in olympic_df['clean_no_stops'].iteritems():\n",
    "\tscore = SentimentIntensityAnalyzer().polarity_scores(' '.join(row))\n",
    "\tneg = score['neg']\n",
    "\tneu = score['neu']\n",
    "\tpos = score['pos']\n",
    "\tcomp = score['compound']\n",
    "\n",
    "\tif comp <= -0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'negative'\n",
    "\telif comp >= 0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'positive'\n",
    "\telse:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'neutral'\n",
    "\t# # Set the values as columns\n",
    "\tolympic_df.loc[index, 'neg'] = neg\n",
    "\tolympic_df.loc[index, 'neu'] = neu\n",
    "\tolympic_df.loc[index, 'pos'] = pos\n",
    "\tolympic_df.loc[index, 'compound'] = comp\n",
    "\n",
    "olympic_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id                created_at  conversation_id  \\\n",
       "0 -1349054463 2021-08-12 18:15:03+00:00      -1349054463   \n",
       "1   429334529 2021-08-12 15:23:44+00:00        429334529   \n",
       "2   -48885760 2021-08-12 14:54:47+00:00        -48885760   \n",
       "3  2115334144 2021-08-12 13:02:47+00:00       2115334144   \n",
       "4  -183029759 2021-08-12 12:36:07+00:00       -183029759   \n",
       "5 -1944776702 2021-08-12 12:26:43+00:00      -1944776702   \n",
       "6   -73945082 2021-08-12 11:49:10+00:00        -73945082   \n",
       "7   156741635 2021-08-12 11:16:04+00:00        156741635   \n",
       "8   517304321 2021-08-12 03:47:08+00:00        517304321   \n",
       "9  -623542263 2021-08-12 01:55:52+00:00       -623542263   \n",
       "\n",
       "                                                text       sport  \\\n",
       "0  Congratulations toüèÖChelsea GrayüèÖon bringing ho...  basketball   \n",
       "1  Talkin‚Äô Noise Podcast - Ep. 9. Will #TeamUSA  ...  basketball   \n",
       "2  üî•üî• High Stakes Takes Locks üî•üî•\\n\\nSTILL on a 12...  basketball   \n",
       "3  Thursday Q&amp;A\\n\\nClick the link in the bio!...  basketball   \n",
       "4  My 1st of three #Olympics themed articles in t...  basketball   \n",
       "5  Great little video about the legend that is Pa...  basketball   \n",
       "6  &gt;US womens basketball team: 7 gold medals \\...  basketball   \n",
       "7  Celebrate the #Olympics by watching #sport mov...  basketball   \n",
       "8  new fc #Dynamite #Olympics #LoveIsland #loveis...  basketball   \n",
       "9  CyberSketch 185\\n\\nDamian Lillard #NBA \\n@Dame...  basketball   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  congratulations tochelsea grayon bringing home...   \n",
       "1  talkin noise podcast  ep  will   basketball te...   \n",
       "2   high stakes takes locks still on a  day strea...   \n",
       "3  thursday qampaclick the link in the bio       ...   \n",
       "4  my st of three  themed articles in this weeks ...   \n",
       "5  great little video about the legend that is pa...   \n",
       "6  gtus womens basketball team  gold medals gtale...   \n",
       "7  celebrate the  by watching  movies            ...   \n",
       "8                          new fc                      \n",
       "9  cybersketch damian lillard    link in bio     ...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [congratulations, tochelsea, grayon, bringing,...   \n",
       "1  [talkin, noise, podcast, ep, basketball, team,...   \n",
       "2  [high, stakes, takes, locks, still, day, strea...   \n",
       "3                  [thursday, qampaclick, link, bio]   \n",
       "4  [st, three, themed, articles, weeks, focuses, ...   \n",
       "5  [great, little, video, legend, patty, looking,...   \n",
       "6  [gtus, womens, basketball, team, gold, medals,...   \n",
       "7                      [celebrate, watching, movies]   \n",
       "8                                          [new, fc]   \n",
       "9          [cybersketch, damian, lillard, link, bio]   \n",
       "\n",
       "                                          lemma_text  polarity  subjectivity  \\\n",
       "0  [congratulations, tochelsea, grayon, bring, ho...  1.000000      1.000000   \n",
       "1  [talkin, noise, podcast, ep, basketball, team,...  0.650000      0.650000   \n",
       "2  [high, stake, take, lock, still, day, streak, ...  0.144242      0.513333   \n",
       "3                  [thursday, qampaclick, link, bio]  0.000000      0.000000   \n",
       "4  [st, three, theme, article, weeks, focus, amaz...  0.500000      0.400000   \n",
       "5  [great, little, video, legend, patty, look, li...  0.146250      0.572500   \n",
       "6  [gtus, womens, basketball, team, gold, medals,...  0.316667      0.408333   \n",
       "7                         [celebrate, watch, movies]  0.000000      0.000000   \n",
       "8                                          [new, fc]  0.136364      0.454545   \n",
       "9          [cybersketch, damian, lillard, link, bio]  0.000000      0.000000   \n",
       "\n",
       "  sentiment  neg    neu    pos  compound  \n",
       "0  positive  0.0  0.456  0.544    0.9493  \n",
       "1  positive  0.0  0.678  0.322    0.5859  \n",
       "2  positive  0.0  0.865  0.135    0.4215  \n",
       "3   neutral  0.0  1.000  0.000    0.0000  \n",
       "4  positive  0.0  0.598  0.402    0.8555  \n",
       "5  positive  0.0  0.661  0.339    0.6249  \n",
       "6  positive  0.0  0.680  0.320    0.7650  \n",
       "7  positive  0.0  0.351  0.649    0.5719  \n",
       "8   neutral  0.0  1.000  0.000    0.0000  \n",
       "9   neutral  0.0  1.000  0.000    0.0000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1349054463</td>\n",
       "      <td>2021-08-12 18:15:03+00:00</td>\n",
       "      <td>-1349054463</td>\n",
       "      <td>Congratulations toüèÖChelsea GrayüèÖon bringing ho...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>congratulations tochelsea grayon bringing home...</td>\n",
       "      <td>[congratulations, tochelsea, grayon, bringing,...</td>\n",
       "      <td>[congratulations, tochelsea, grayon, bring, ho...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429334529</td>\n",
       "      <td>2021-08-12 15:23:44+00:00</td>\n",
       "      <td>429334529</td>\n",
       "      <td>Talkin‚Äô Noise Podcast - Ep. 9. Will #TeamUSA  ...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>talkin noise podcast  ep  will   basketball te...</td>\n",
       "      <td>[talkin, noise, podcast, ep, basketball, team,...</td>\n",
       "      <td>[talkin, noise, podcast, ep, basketball, team,...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48885760</td>\n",
       "      <td>2021-08-12 14:54:47+00:00</td>\n",
       "      <td>-48885760</td>\n",
       "      <td>üî•üî• High Stakes Takes Locks üî•üî•\\n\\nSTILL on a 12...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>high stakes takes locks still on a  day strea...</td>\n",
       "      <td>[high, stakes, takes, locks, still, day, strea...</td>\n",
       "      <td>[high, stake, take, lock, still, day, streak, ...</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2115334144</td>\n",
       "      <td>2021-08-12 13:02:47+00:00</td>\n",
       "      <td>2115334144</td>\n",
       "      <td>Thursday Q&amp;amp;A\\n\\nClick the link in the bio!...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>thursday qampaclick the link in the bio       ...</td>\n",
       "      <td>[thursday, qampaclick, link, bio]</td>\n",
       "      <td>[thursday, qampaclick, link, bio]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-183029759</td>\n",
       "      <td>2021-08-12 12:36:07+00:00</td>\n",
       "      <td>-183029759</td>\n",
       "      <td>My 1st of three #Olympics themed articles in t...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>my st of three  themed articles in this weeks ...</td>\n",
       "      <td>[st, three, themed, articles, weeks, focuses, ...</td>\n",
       "      <td>[st, three, theme, article, weeks, focus, amaz...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1944776702</td>\n",
       "      <td>2021-08-12 12:26:43+00:00</td>\n",
       "      <td>-1944776702</td>\n",
       "      <td>Great little video about the legend that is Pa...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>great little video about the legend that is pa...</td>\n",
       "      <td>[great, little, video, legend, patty, looking,...</td>\n",
       "      <td>[great, little, video, legend, patty, look, li...</td>\n",
       "      <td>0.146250</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-73945082</td>\n",
       "      <td>2021-08-12 11:49:10+00:00</td>\n",
       "      <td>-73945082</td>\n",
       "      <td>&amp;gt;US womens basketball team: 7 gold medals \\...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>gtus womens basketball team  gold medals gtale...</td>\n",
       "      <td>[gtus, womens, basketball, team, gold, medals,...</td>\n",
       "      <td>[gtus, womens, basketball, team, gold, medals,...</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156741635</td>\n",
       "      <td>2021-08-12 11:16:04+00:00</td>\n",
       "      <td>156741635</td>\n",
       "      <td>Celebrate the #Olympics by watching #sport mov...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>celebrate the  by watching  movies            ...</td>\n",
       "      <td>[celebrate, watching, movies]</td>\n",
       "      <td>[celebrate, watch, movies]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>517304321</td>\n",
       "      <td>2021-08-12 03:47:08+00:00</td>\n",
       "      <td>517304321</td>\n",
       "      <td>new fc #Dynamite #Olympics #LoveIsland #loveis...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>new fc</td>\n",
       "      <td>[new, fc]</td>\n",
       "      <td>[new, fc]</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-623542263</td>\n",
       "      <td>2021-08-12 01:55:52+00:00</td>\n",
       "      <td>-623542263</td>\n",
       "      <td>CyberSketch 185\\n\\nDamian Lillard #NBA \\n@Dame...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>cybersketch damian lillard    link in bio     ...</td>\n",
       "      <td>[cybersketch, damian, lillard, link, bio]</td>\n",
       "      <td>[cybersketch, damian, lillard, link, bio]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Cache results\n",
    "with open('../data/checkpoints/olympic-tweets-post-sentiment.pkl', 'wb') as f:\n",
    "\tpickle.dump(olympic_df, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"container\">\n",
    "   <div style=\"float:left;width:20%\"><a href=\"./Cleaning.ipynb\"><< Section 3: Data Cleaning</a></div>\n",
    "   <div style=\"float:right;width:25%\"><a href=\"./Eval.ipynb\">Section 5: Evaluation and Conclusions >></a></div>\n",
    "   <div style=\"float:right;width:35%\"><a href=\"../main.md\">Table of Contents</a></div>\n",
    "</div>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}