{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Section 4: Model Creation\n",
    "\n",
    "- [Section 4.1: Model](#model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4.1: Model <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "### Background\n",
    "\n",
    "To provide sentiment analysis for tweet data, we utilize two packages: (1) TextBlob and (2) VADER from the NLTK toolkit. TextBlob provides a simple interface for processing text-based data and allows for the calculation of the subjectivity and polarity for a given text, which will aid in sentiment analysis using a set of additional text features. The VADER model is a pre-trained model that uses rule-based values which are especially attuned to sentiments from social media, making it a great choice for overall sentiment analysis. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Read data from pickled checkpoint\n",
    "olympic_df = pd.read_pickle('../data/checkpoints/olympic-tweets-pre-sentiment.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Lemmatize prior to sentiment analysis\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "olympic_df['lemma_text'] = olympic_df.clean_no_stops.apply(lambda text: [ wn_lemmatizer.lemmatize(word, pos='v') for word in text ])\n",
    "olympic_df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               id                created_at  conversation_id  \\\n",
       "10328  1851019264 2021-07-25 08:29:08+00:00                0   \n",
       "28717  1834242052 2021-08-07 12:40:25+00:00       1834242052   \n",
       "29680 -1340768250 2021-08-06 06:38:19+00:00      -1340768250   \n",
       "21991 -1152102394 2021-08-08 04:53:07+00:00      -1152102394   \n",
       "28283 -1252765695 2021-08-07 14:49:35+00:00      -1252765695   \n",
       "\n",
       "                                                    text       sport  \\\n",
       "10328  RT @Olympics: Anna Kiesenhofer of #AUT takes #...      biking   \n",
       "28717  How do you enjoy #Tokyo2020 #olympics? It's th...  volleyball   \n",
       "29680  #Olympics #volleyball #Usa #Vs #AUS   #Gold #T...  volleyball   \n",
       "21991  History has been made as NeerajChopra fulfils ...       track   \n",
       "28283  What a game!! Congrats, #FRA for winning gold!...  volleyball   \n",
       "\n",
       "                                              clean_text  \\\n",
       "10328  rt  anna kiesenhofer of  takes  in the  womens...   \n",
       "28717  how do you enjoy   its the week of major final      \n",
       "29680                  whats that relative to a high ...   \n",
       "21991  history has been made as neerajchopra fulfils ...   \n",
       "28283  what a game congrats  for winning gold kudos t...   \n",
       "\n",
       "                                          clean_no_stops  \\\n",
       "10328  [rt, anna, kiesenhofer, takes, womens, road, r...   \n",
       "28717                        [enjoy, week, major, final]   \n",
       "29680        [whats, relative, high, school, high, dive]   \n",
       "21991  [history, made, neerajchopra, fulfils, dream, ...   \n",
       "28283  [game, congrats, winning, gold, kudos, solid, ...   \n",
       "\n",
       "                                              lemma_text  \n",
       "10328  [rt, anna, kiesenhofer, take, womens, road, ra...  \n",
       "28717                        [enjoy, week, major, final]  \n",
       "29680        [whats, relative, high, school, high, dive]  \n",
       "21991  [history, make, neerajchopra, fulfil, dream, e...  \n",
       "28283  [game, congrats, win, gold, kudos, solid, figh...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>1851019264</td>\n",
       "      <td>2021-07-25 08:29:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @Olympics: Anna Kiesenhofer of #AUT takes #...</td>\n",
       "      <td>biking</td>\n",
       "      <td>rt  anna kiesenhofer of  takes  in the  womens...</td>\n",
       "      <td>[rt, anna, kiesenhofer, takes, womens, road, r...</td>\n",
       "      <td>[rt, anna, kiesenhofer, take, womens, road, ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28717</th>\n",
       "      <td>1834242052</td>\n",
       "      <td>2021-08-07 12:40:25+00:00</td>\n",
       "      <td>1834242052</td>\n",
       "      <td>How do you enjoy #Tokyo2020 #olympics? It's th...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>how do you enjoy   its the week of major final</td>\n",
       "      <td>[enjoy, week, major, final]</td>\n",
       "      <td>[enjoy, week, major, final]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29680</th>\n",
       "      <td>-1340768250</td>\n",
       "      <td>2021-08-06 06:38:19+00:00</td>\n",
       "      <td>-1340768250</td>\n",
       "      <td>#Olympics #volleyball #Usa #Vs #AUS   #Gold #T...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>whats that relative to a high ...</td>\n",
       "      <td>[whats, relative, high, school, high, dive]</td>\n",
       "      <td>[whats, relative, high, school, high, dive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21991</th>\n",
       "      <td>-1152102394</td>\n",
       "      <td>2021-08-08 04:53:07+00:00</td>\n",
       "      <td>-1152102394</td>\n",
       "      <td>History has been made as NeerajChopra fulfils ...</td>\n",
       "      <td>track</td>\n",
       "      <td>history has been made as neerajchopra fulfils ...</td>\n",
       "      <td>[history, made, neerajchopra, fulfils, dream, ...</td>\n",
       "      <td>[history, make, neerajchopra, fulfil, dream, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28283</th>\n",
       "      <td>-1252765695</td>\n",
       "      <td>2021-08-07 14:49:35+00:00</td>\n",
       "      <td>-1252765695</td>\n",
       "      <td>What a game!! Congrats, #FRA for winning gold!...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>what a game congrats  for winning gold kudos t...</td>\n",
       "      <td>[game, congrats, winning, gold, kudos, solid, ...</td>\n",
       "      <td>[game, congrats, win, gold, kudos, solid, figh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentiment Calculation\n",
    "\n",
    "From the output of TextBlob, we generate two additional features for use in our analysis:\n",
    "* Polarity: a measure ([-1, 1]) of the sentiment of a text; higher polarity means the text contains more positive sentiment.\n",
    "* Subjectivity: a measure ([0, 1]) of the opinion and factual information contained in a text; higher subjectivity means the text contains more personal opinion.\n",
    "\n",
    "From the output of VADER, we generate three additional features for use in our analysis:\n",
    "* Neg, Neu, and Pos are scores for the ratios for proportions of text that fall into a negative, neutral, and positive sentiment.\n",
    "* Compound: a score computed by summing the valence scores of each word in the VADER lexicon and normalized to create a composite sentiment score.\n",
    "* Sentiment: a categorical column that standardizes/generalizes the compound score into positive, neutral, and negative sentiment values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Calculating polarity and subjectivity\n",
    "olympic_df[['polarity', 'subjectivity']] = olympic_df['lemma_text'].apply(lambda text: pd.Series(TextBlob(' '.join(text)).sentiment))\n",
    "\n",
    "# Calculating Negative, Positive, Neutral and Compound values\n",
    "for index, row in olympic_df['clean_no_stops'].iteritems():\n",
    "\tscore = SentimentIntensityAnalyzer().polarity_scores(' '.join(row))\n",
    "\tneg = score['neg']\n",
    "\tneu = score['neu']\n",
    "\tpos = score['pos']\n",
    "\tcomp = score['compound']\n",
    "\n",
    "\tif comp <= -0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'negative'\n",
    "\telif comp >= 0.05:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'positive'\n",
    "\telif:\n",
    "\t\tolympic_df.loc[index, 'sentiment'] = 'neutral'\n",
    "\t# # Set the values as columns\n",
    "\tolympic_df.loc[index, 'neg'] = neg\n",
    "\tolympic_df.loc[index, 'neu'] = neu\n",
    "\tolympic_df.loc[index, 'pos'] = pos\n",
    "\tolympic_df.loc[index, 'compound'] = comp\n",
    "\n",
    "olympic_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id                created_at  conversation_id  \\\n",
       "0 -1349054463 2021-08-12 18:15:03+00:00      -1349054463   \n",
       "1   429334529 2021-08-12 15:23:44+00:00        429334529   \n",
       "2   -48885760 2021-08-12 14:54:47+00:00        -48885760   \n",
       "3  2115334144 2021-08-12 13:02:47+00:00       2115334144   \n",
       "4  -183029759 2021-08-12 12:36:07+00:00       -183029759   \n",
       "5 -1944776702 2021-08-12 12:26:43+00:00      -1944776702   \n",
       "6   -73945082 2021-08-12 11:49:10+00:00        -73945082   \n",
       "7   156741635 2021-08-12 11:16:04+00:00        156741635   \n",
       "8   517304321 2021-08-12 03:47:08+00:00        517304321   \n",
       "9  -623542263 2021-08-12 01:55:52+00:00       -623542263   \n",
       "\n",
       "                                                text       sport  \\\n",
       "0  Congratulations to🏅Chelsea Gray🏅on bringing ho...  basketball   \n",
       "1  Talkin’ Noise Podcast - Ep. 9. Will #TeamUSA  ...  basketball   \n",
       "2  🔥🔥 High Stakes Takes Locks 🔥🔥\\n\\nSTILL on a 12...  basketball   \n",
       "3  Thursday Q&amp;A\\n\\nClick the link in the bio!...  basketball   \n",
       "4  My 1st of three #Olympics themed articles in t...  basketball   \n",
       "5  Great little video about the legend that is Pa...  basketball   \n",
       "6  &gt;US womens basketball team: 7 gold medals \\...  basketball   \n",
       "7  Celebrate the #Olympics by watching #sport mov...  basketball   \n",
       "8  new fc #Dynamite #Olympics #LoveIsland #loveis...  basketball   \n",
       "9  CyberSketch 185\\n\\nDamian Lillard #NBA \\n@Dame...  basketball   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  congratulations tochelsea grayon bringing home...   \n",
       "1  talkin noise podcast  ep  will   basketball te...   \n",
       "2   high stakes takes locks still on a  day strea...   \n",
       "3  thursday qampaclick the link in the bio       ...   \n",
       "4  my st of three  themed articles in this weeks ...   \n",
       "5  great little video about the legend that is pa...   \n",
       "6  gtus womens basketball team  gold medals gtale...   \n",
       "7  celebrate the  by watching  movies            ...   \n",
       "8                          new fc                      \n",
       "9  cybersketch damian lillard    link in bio     ...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [congratulations, tochelsea, grayon, bringing,...   \n",
       "1  [talkin, noise, podcast, ep, basketball, team,...   \n",
       "2  [high, stakes, takes, locks, still, day, strea...   \n",
       "3                  [thursday, qampaclick, link, bio]   \n",
       "4  [st, three, themed, articles, weeks, focuses, ...   \n",
       "5  [great, little, video, legend, patty, looking,...   \n",
       "6  [gtus, womens, basketball, team, gold, medals,...   \n",
       "7                      [celebrate, watching, movies]   \n",
       "8                                          [new, fc]   \n",
       "9          [cybersketch, damian, lillard, link, bio]   \n",
       "\n",
       "                                          lemma_text  polarity  subjectivity  \\\n",
       "0  [congratulations, tochelsea, grayon, bring, ho...  1.000000      1.000000   \n",
       "1  [talkin, noise, podcast, ep, basketball, team,...  0.650000      0.650000   \n",
       "2  [high, stake, take, lock, still, day, streak, ...  0.144242      0.513333   \n",
       "3                  [thursday, qampaclick, link, bio]  0.000000      0.000000   \n",
       "4  [st, three, theme, article, weeks, focus, amaz...  0.500000      0.400000   \n",
       "5  [great, little, video, legend, patty, look, li...  0.146250      0.572500   \n",
       "6  [gtus, womens, basketball, team, gold, medals,...  0.316667      0.408333   \n",
       "7                         [celebrate, watch, movies]  0.000000      0.000000   \n",
       "8                                          [new, fc]  0.136364      0.454545   \n",
       "9          [cybersketch, damian, lillard, link, bio]  0.000000      0.000000   \n",
       "\n",
       "  sentiment  neg    neu    pos  compound  \n",
       "0  positive  0.0  0.456  0.544    0.9493  \n",
       "1  positive  0.0  0.678  0.322    0.5859  \n",
       "2  positive  0.0  0.865  0.135    0.4215  \n",
       "3   neutral  0.0  1.000  0.000    0.0000  \n",
       "4  positive  0.0  0.598  0.402    0.8555  \n",
       "5  positive  0.0  0.661  0.339    0.6249  \n",
       "6  positive  0.0  0.680  0.320    0.7650  \n",
       "7  positive  0.0  0.351  0.649    0.5719  \n",
       "8   neutral  0.0  1.000  0.000    0.0000  \n",
       "9   neutral  0.0  1.000  0.000    0.0000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sport</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1349054463</td>\n",
       "      <td>2021-08-12 18:15:03+00:00</td>\n",
       "      <td>-1349054463</td>\n",
       "      <td>Congratulations to🏅Chelsea Gray🏅on bringing ho...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>congratulations tochelsea grayon bringing home...</td>\n",
       "      <td>[congratulations, tochelsea, grayon, bringing,...</td>\n",
       "      <td>[congratulations, tochelsea, grayon, bring, ho...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429334529</td>\n",
       "      <td>2021-08-12 15:23:44+00:00</td>\n",
       "      <td>429334529</td>\n",
       "      <td>Talkin’ Noise Podcast - Ep. 9. Will #TeamUSA  ...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>talkin noise podcast  ep  will   basketball te...</td>\n",
       "      <td>[talkin, noise, podcast, ep, basketball, team,...</td>\n",
       "      <td>[talkin, noise, podcast, ep, basketball, team,...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48885760</td>\n",
       "      <td>2021-08-12 14:54:47+00:00</td>\n",
       "      <td>-48885760</td>\n",
       "      <td>🔥🔥 High Stakes Takes Locks 🔥🔥\\n\\nSTILL on a 12...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>high stakes takes locks still on a  day strea...</td>\n",
       "      <td>[high, stakes, takes, locks, still, day, strea...</td>\n",
       "      <td>[high, stake, take, lock, still, day, streak, ...</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2115334144</td>\n",
       "      <td>2021-08-12 13:02:47+00:00</td>\n",
       "      <td>2115334144</td>\n",
       "      <td>Thursday Q&amp;amp;A\\n\\nClick the link in the bio!...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>thursday qampaclick the link in the bio       ...</td>\n",
       "      <td>[thursday, qampaclick, link, bio]</td>\n",
       "      <td>[thursday, qampaclick, link, bio]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-183029759</td>\n",
       "      <td>2021-08-12 12:36:07+00:00</td>\n",
       "      <td>-183029759</td>\n",
       "      <td>My 1st of three #Olympics themed articles in t...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>my st of three  themed articles in this weeks ...</td>\n",
       "      <td>[st, three, themed, articles, weeks, focuses, ...</td>\n",
       "      <td>[st, three, theme, article, weeks, focus, amaz...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1944776702</td>\n",
       "      <td>2021-08-12 12:26:43+00:00</td>\n",
       "      <td>-1944776702</td>\n",
       "      <td>Great little video about the legend that is Pa...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>great little video about the legend that is pa...</td>\n",
       "      <td>[great, little, video, legend, patty, looking,...</td>\n",
       "      <td>[great, little, video, legend, patty, look, li...</td>\n",
       "      <td>0.146250</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-73945082</td>\n",
       "      <td>2021-08-12 11:49:10+00:00</td>\n",
       "      <td>-73945082</td>\n",
       "      <td>&amp;gt;US womens basketball team: 7 gold medals \\...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>gtus womens basketball team  gold medals gtale...</td>\n",
       "      <td>[gtus, womens, basketball, team, gold, medals,...</td>\n",
       "      <td>[gtus, womens, basketball, team, gold, medals,...</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156741635</td>\n",
       "      <td>2021-08-12 11:16:04+00:00</td>\n",
       "      <td>156741635</td>\n",
       "      <td>Celebrate the #Olympics by watching #sport mov...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>celebrate the  by watching  movies            ...</td>\n",
       "      <td>[celebrate, watching, movies]</td>\n",
       "      <td>[celebrate, watch, movies]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>517304321</td>\n",
       "      <td>2021-08-12 03:47:08+00:00</td>\n",
       "      <td>517304321</td>\n",
       "      <td>new fc #Dynamite #Olympics #LoveIsland #loveis...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>new fc</td>\n",
       "      <td>[new, fc]</td>\n",
       "      <td>[new, fc]</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-623542263</td>\n",
       "      <td>2021-08-12 01:55:52+00:00</td>\n",
       "      <td>-623542263</td>\n",
       "      <td>CyberSketch 185\\n\\nDamian Lillard #NBA \\n@Dame...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>cybersketch damian lillard    link in bio     ...</td>\n",
       "      <td>[cybersketch, damian, lillard, link, bio]</td>\n",
       "      <td>[cybersketch, damian, lillard, link, bio]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Cache results\n",
    "with open('../data/checkpoints/olympic-tweets-post-sentiment.pkl', 'wb') as f:\n",
    "\tpickle.dump(olympic_df, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"container\">\n",
    "   <div style=\"float:left;width:20%\"><a href=\"./Cleaning.ipynb\"><< Section 3: Data Cleaning</a></div>\n",
    "   <div style=\"float:right;width:25%\"><a href=\"./Eval.ipynb\">Section 5: Evaluation and Conclusions >></a></div>\n",
    "   <div style=\"float:right;width:35%\"><a href=\"../main.md\">Table of Contents</a></div>\n",
    "</div>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}